#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
train_pick.py
-------------
è¨“ç·´å¤šé¡åˆ¥ LightGBMï¼Œè¼¸å‡ºï¼š
  models/pick_lgb.txt         â† LightGBM åŸç”Ÿæ¨¡å‹
  models/pick_encoder.pkl     â† champ LabelEncoder
  reports/pick_cv.txt         â† äº¤å‰é©—è­‰çµæœ
"""

import pandas as pd, numpy as np, lightgbm as lgb, joblib, optuna
from pathlib import Path
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GroupKFold
from sklearn.metrics import accuracy_score, top_k_accuracy_score

ROOT   = Path(__file__).resolve().parents[1]
DATA   = ROOT / "output"  / "pick_dataset.parquet"
MODEL  = ROOT / "models";  MODEL.mkdir(exist_ok=True)
REPORT = ROOT / "reports"; REPORT.mkdir(exist_ok=True)

##############################################
# 1. è¼‰å…¥è³‡æ–™
##############################################
df = pd.read_parquet(DATA)

# è§£æå­—ä¸² â†’ list[int]
def to_int_list(s):
    """æŠŠ '1,2,3' â†’ [1,2,3]ï¼›æŠŠéæ•´æ•¸ token (å¦‚ 'ban1') ç›´æ¥éæ¿¾æ‰"""
    if not isinstance(s, str) or s.strip() == "":
        return []
    out = []
    for tok in s.split(","):
        tok = tok.strip()
        if tok.isdigit():
            out.append(int(tok))
    return out

df["teampicks"] = df["teampicks"].apply(to_int_list)
df["teambans"]  = df["teambans"]. apply(to_int_list)

# champion label ç·¨ç¢¼
le = LabelEncoder().fit(df["label"])
df["label_enc"] = le.transform(df["label"])
NUM_CLASS = len(le.classes_)

##############################################
# 2. ç‰¹å¾µå·¥ç¨‹ï¼šå°‡ 5 picks + 5 bans padding æˆé•·åº¦ 5
##############################################
MAX_PICK = 5
feat_cols = []

def pad(lst, max_len=MAX_PICK):
    return lst + [0]*(max_len-len(lst))

for i in range(MAX_PICK):
    df[f"pick_{i+1}"] = df["teampicks"].apply(lambda l: pad(l)[i])
    df[f"ban_{i+1}"]  = df["teambans"]. apply(lambda l: pad(l)[i])
    feat_cols.extend([f"pick_{i+1}", f"ban_{i+1}"])

df["pick_order"] = df["pick_order"].astype(np.int8)
feat_cols.append("pick_order")

X = df[feat_cols]
y = df["label_enc"]
groups = df["matchid"]        # é˜²æ´©æ¼ï¼šåŒå ´è³‡æ–™åŒ fold

##############################################
# 3. Optuna è¶…åƒæœå°‹ + 5 fold GroupKFold
##############################################
def objective(trial):
    params = {
        "objective": "multiclass",
        "metric": "multi_logloss",
        "num_class": NUM_CLASS,
        "learning_rate": trial.suggest_float("lr", 0.02, 0.2, log=True),
        "num_leaves": trial.suggest_int("num_leaves", 31, 255, step=16),
        "feature_fraction": trial.suggest_float("ff", 0.6, 1.0),
        "min_data_in_leaf": trial.suggest_int("min_data", 20, 200),
        "verbosity": -1,
        "seed": 42
    }

    cv_acc, cv_top5 = [], []
    gkf = GroupKFold(n_splits=5)
    for train_idx, val_idx in gkf.split(X, y, groups):
        lgb_train = lgb.Dataset(X.iloc[train_idx], label=y.iloc[train_idx])
        lgb_val   = lgb.Dataset(X.iloc[val_idx],   label=y.iloc[val_idx])

        model = lgb.train(
    params,
    lgb_train,
    num_boost_round=100,
    valid_sets=[lgb_val],
    callbacks=[
        lgb.early_stopping(stopping_rounds=20),
        lgb.log_evaluation(period=10)   # ç›¸ç•¶æ–¼ verbose_eval=False
    ]
)

        pred = model.predict(X.iloc[val_idx])
        cv_acc.append(accuracy_score(y.iloc[val_idx], np.argmax(pred, 1)))
        cv_top5.append(top_k_accuracy_score(y.iloc[val_idx], pred, k=5))

    trial.set_user_attr("acc",   np.mean(cv_acc))
    trial.set_user_attr("top5",  np.mean(cv_top5))
    return 1 - np.mean(cv_top5)      # ä»¥ top-5 Accuracy åšå„ªåŒ–

study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=30, timeout=1800)   # 30 æ¬¡ or 30 åˆ†é˜

best_params = study.best_trial.params
best_params.update({"objective":"multiclass","metric":"multi_logloss",
                    "num_class":NUM_CLASS,"verbosity":-1,"seed":42})

##############################################
# 4. ç”¨æœ€ä½³åƒæ•¸å…¨è³‡æ–™å†è¨“ç·´ä¸€æ¬¡
##############################################
train_set = lgb.Dataset(X, label=y)
final_model = lgb.train(best_params, train_set, num_boost_round=study.best_trial.user_attrs.get("best_iter", 150))

##############################################
# 5. å„²å­˜æ¨¡å‹ & å ±å‘Š
##############################################
final_model.save_model(str(MODEL / "pick_lgb.txt"))
joblib.dump(le, MODEL / "pick_encoder.pkl")

with open(REPORT / "pick_cv.txt", "w", encoding="utf-8") as f:
    t = study.best_trial
    f.write(f"Best top-1 ACC  : {t.user_attrs['acc']:.4f}\n")
    f.write(f"Best top-5 ACC : {t.user_attrs['top5']:.4f}\n")
    f.write(f"Params         : {best_params}\n")

print("ğŸ‰ æ¨¡å‹è¨“ç·´å®Œæˆï¼")
print("  âœ æ¨¡å‹æª”  :", MODEL / 'pick_lgb.txt')
print("  âœ Encoder :", MODEL / 'pick_encoder.pkl')
print("  âœ å ±å‘Š     :", REPORT / 'pick_cv.txt')
