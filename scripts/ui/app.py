# working version
"""
Streamlit App â€” BanPick æ¨è–¦ UIï¼ˆåŒ…å« AI æ¨è–¦ + å‹ç‡é æ¸¬ + Red æ–¹è¼¸å…¥åŠ æ¬Šï¼‰
"""

import streamlit as st
st.set_page_config(layout="wide", page_title="LoL BanPick æ§åˆ¶ä»‹é¢")
import pandas as pd
import numpy as np
import lightgbm as lgb
import joblib
from pathlib import Path
import asyncio
import aiohttp
import requests
import time
from collections import Counter


# ---------- ä½¿ç”¨è€…è¼¸å…¥ Riot ID ----------
st.markdown("### ğŸ” è¼¸å…¥ Riot ID ä»¥é€²è¡Œå€‹äººåŒ–æ¨è–¦")
riot_id = st.text_input("Riot ID", value="Hikaru", key="riot_input")
tag_line = st.text_input("Tag Line", value="0706", key="tag_input")
API_KEY = "RGAPI-c4e80e58-0ae6-4a6d-96f8-6999b2976c9b"
headers = {"X-Riot-Token": API_KEY}

@st.cache_data
def get_champion_id_name_map():
    url = "https://ddragon.leagueoflegends.com/cdn/14.9.1/data/en_US/champion.json"
    res = requests.get(url)
    if res.status_code != 200:
        st.error("âŒ Failed to load champion list")
        return {}
    data = res.json()["data"]
    return {int(info["key"]): name for name, info in data.items()}

@st.cache_data
def get_puuid(riot_id, tag_line):
    url = f"https://asia.api.riotgames.com/riot/account/v1/accounts/by-riot-id/{riot_id}/{tag_line}"
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        return res.json()["puuid"]
    return None

def get_match_ids(puuid, total=50):
    all_ids = []
    for start in range(0, total, 100):
        url = f"https://sea.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids?start={start}&count=100"
        res = requests.get(url, headers=headers)
        if res.status_code == 200:
            all_ids.extend(res.json())
        else:
            break
        time.sleep(1)
    return all_ids

async def fetch_match(session, match_id, sem):
    url = f"https://sea.api.riotgames.com/lol/match/v5/matches/{match_id}"
    async with sem:
        async with session.get(url, headers=headers) as res:
            if res.status == 200:
                return await res.json()
            return None

async def fetch_all_matches(match_ids):
    sem = asyncio.Semaphore(10)
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_match(session, mid, sem) for mid in match_ids]
        return await asyncio.gather(*tasks)

def collect_player_stats(puuid, match_data):
    records = []
    for match in match_data:
        if not match:
            continue
        for p in match["info"]["participants"]:
            if p["puuid"] == puuid:
                records.append({
                    "champion": p["championName"],
                    "win": p["win"]
                })
                break
    return pd.DataFrame(records)

@st.cache_data
def get_personal_winrates(riot_id, tag_line):
    puuid = get_puuid(riot_id, tag_line)
    if not puuid:
        return {}
    match_ids = get_match_ids(puuid, total=50)
    match_data = asyncio.run(fetch_all_matches(match_ids))
    df = collect_player_stats(puuid, match_data)
    if df.empty:
        return {}
    win_df = df.groupby("champion").agg(count=("win", "count"), winrate=("win", "mean")).reset_index()
    boost_map = {}
    for _, row in win_df.iterrows():
        if row["winrate"] > 0.6:
            boost_map[row["champion"]] = 0.1
        elif row["winrate"] < 0.4:
            boost_map[row["champion"]] = -0.1
    return boost_map

# ğŸ”§ å–å¾— boost mapï¼ˆåœ¨æ¨è–¦å‰å‘¼å«ï¼‰
champion_map = get_champion_id_name_map()
personal_boost = get_personal_winrates(riot_id, tag_line)


# ---------- è·¯å¾‘èˆ‡è³‡æ–™è¼‰å…¥ ----------
ROOT = Path(__file__).resolve().parents[2]
DATA = ROOT / "data"
MODEL = ROOT / "models"
OUTPUT = ROOT / "output"

# è®€å–è‹±é›„åç¨±å°æ‡‰è¡¨
try:
    champs_df = pd.read_csv(DATA / "champs.csv")
    champ_name_map = champs_df.set_index("id")["name"].to_dict()
except Exception as e:
    st.error(f"âŒ ç„¡æ³•è¼‰å…¥è‹±é›„åç¨±å°æ‡‰è¡¨ï¼š{DATA / 'champs.csv'}\néŒ¯èª¤è¨Šæ¯ï¼š{e}")
    st.stop()

# è®€å–æ¨è–¦æ¨¡å‹ï¼ˆPick æ¨¡å‹ï¼‰èˆ‡ç·¨ç¢¼å™¨
try:
    pick_model = lgb.Booster(model_file=str(MODEL / "pick_lgb_v3.txt"))
    encoder = joblib.load(MODEL / "pick_encoder_v3.pkl")
except Exception as e:
    st.error(f"âŒ æ¨è–¦æ¨¡å‹æˆ–ç·¨ç¢¼å™¨è¼‰å…¥éŒ¯èª¤ï¼š{e}")
    st.stop()

# è®€å–å‹ç‡é æ¸¬æ¨¡å‹ï¼ˆåƒ…ä½¿ç”¨ CPU-only ç‰ˆï¼Œé¿å… GPU ç‰ˆåœ¨æ­¤ç’°å¢ƒä¸‹å´©æ½°ï¼‰
try:
    wr_model = lgb.Booster(model_file=str(MODEL / "wr_lgb_v5_cpu.txt"))
    wr_features = wr_model.feature_name()
except Exception as e:
    st.error(f"âŒ å‹ç‡é æ¸¬æ¨¡å‹è¼‰å…¥éŒ¯èª¤ï¼š{e}")
    st.stop()
# ---------- è®€å– merged_output.csvï¼ˆç”¨æ–¼ bp_wr* / rp_wr*ï¼‰ ----------
WR_CSV = ROOT / "scripts" / "merged_output.csv"        # â† èˆ‡ app.py åŒè³‡æ–™å¤¾
try:
    wr_df = pd.read_csv(WR_CSV)
    # ä¾‹ï¼šWin % æ¬„æ˜¯ "58.11%" â†’ 0.5811
    wr_df["win_rate"] = wr_df["Win %"].str.rstrip("%").astype(float) / 100.0
    WINRATE_LOOKUP = wr_df.set_index("Champion ID")["win_rate"].to_dict()
except Exception as e:
    st.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥ {WR_CSV.name}ï¼š{e}ï¼ˆå°‡ä½¿ç”¨ 0.5 ä½œç‚ºé è¨­ï¼‰")
    WINRATE_LOOKUP = {}

# ---------- åŠŸèƒ½å‡½å¼ ----------


def id_to_name(cid):
    try:
        return champ_name_map.get(int(cid), f"ID {cid}")
    except:
        return f"ID {cid}"


def clean_ids(raw_list):
    cleaned = []
    for item in raw_list:
        try:
            cleaned.append(int(str(item).strip()))
        except:
            continue
    return cleaned


def pad(lst, l=5):
    # æŠŠå·²æœ‰çš„ IDs å–å‰ l å€‹ï¼Œè‹¥ä¸è¶³å°±è£œ 0
    return (clean_ids(lst) + [0] * l)[:l]


# ---------- æ‰€æœ‰è‹±é›„é¸é … ----------
champ_options = sorted([str(cid) for cid in champ_name_map.keys()])

# ---------- multiselect åŒ…è£å‡½å¼ ----------


def safe_multiselect(label, options, key, filter_ids=None):
    filter_ids = filter_ids or []
    options_cleaned = [cid for cid in options if int(cid) not in filter_ids]
    default_values = [cid for cid in st.session_state.get(
        key, []) if cid in options_cleaned]
    return st.sidebar.multiselect(
        label,
        options=options_cleaned,
        default=default_values,
        key=key,
        format_func=id_to_name
    )


# ---------- å´é‚Šè¼¸å…¥é¸å–® ----------
st.sidebar.header("ğŸ”µ è—æ–¹ Picks / Bans")
blue_bans = safe_multiselect(
    "è—æ–¹ Ban", champ_options, key="bb",
    filter_ids=clean_ids(st.session_state.get("rb", []))
)
blue_picks = safe_multiselect(
    "è—æ–¹ Pick", champ_options, key="bp",
    filter_ids=clean_ids(st.session_state.get(
        "rb", []) + st.session_state.get("bb", []))
)

st.sidebar.header("ğŸ”´ ç´…æ–¹ Picks / Bans")
red_bans = safe_multiselect(
    "ç´…æ–¹ Ban", champ_options, key="rb",
    filter_ids=clean_ids(st.session_state.get("bb", []))
)
red_picks = safe_multiselect(
    "ç´…æ–¹ Pick", champ_options, key="rp",
    filter_ids=clean_ids(st.session_state.get(
        "bb", []) + st.session_state.get("rb", []))
)

# ---------- é¡¯ç¤º Ban / Pick ç¾æ³ ----------
st.markdown("## ğŸ“Š Ban / Pick ç¾æ³")


def ids_to_names(id_list):
    return [id_to_name(cid) for cid in clean_ids(id_list)]


ban_blue_list = ids_to_names(st.session_state.get("bb", []))
ban_red_list = ids_to_names(st.session_state.get("rb", []))
pick_blue_list = ids_to_names(st.session_state.get("bp", []))
pick_red_list = ids_to_names(st.session_state.get("rp", []))

max_len = max(len(ban_blue_list), len(ban_red_list),
              len(pick_blue_list), len(pick_red_list))

ban_data = {
    "è—æ–¹ Ban": ban_blue_list + [""] * (max_len - len(ban_blue_list)),
    "ç´…æ–¹ Ban": ban_red_list + [""] * (max_len - len(ban_red_list))
}
pick_data_blue = {
    "è—æ–¹ Pick": pick_blue_list + [""] * (max_len - len(pick_blue_list))
}
pick_data_red = {
    "ç´…æ–¹ Pick": pick_red_list + [""] * (max_len - len(pick_red_list))
}

col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("### ğŸš« Ban ç‹€æ³")
    st.table(pd.DataFrame(ban_data))
with col2:
    st.markdown("### ğŸ”µ è—æ–¹ Pick ç‹€æ³")
    st.table(pd.DataFrame(pick_data_blue))
with col3:
    st.markdown("### ğŸ”´ ç´…æ–¹ Pick ç‹€æ³")
    st.table(pd.DataFrame(pick_data_red))

# ---------- ğŸ¯ æ¨è–¦è‹±é›„ Top-5 ----------
blue_pick_ids = clean_ids(st.session_state.get("bp", []))
red_pick_ids = clean_ids(st.session_state.get("rp", []))
ban_ids = clean_ids(st.session_state.get("bb", []) +
                    st.session_state.get("rb", []))
pick_features = pick_model.feature_name()

# å»ºç«‹è¼¸å…¥çµ¦æ¨è–¦æ¨¡å‹çš„ç‰¹å¾µè¡¨
x_rec = {}
for i in range(5):
    x_rec[f"pick_{i+1}"] = pad(blue_pick_ids)[i]
    x_rec[f"ban_{i+1}"] = pad(ban_ids)[i]
    # æ¨è–¦æ¨¡å‹çš„ wr æ¬„ä½æ²’åœ¨ç”¨ï¼Œè¨­ç‚º 0
    x_rec[f"pick_wr{i+1}"] = 0
    x_rec[f"ban_wr{i+1}"] = 0
x_rec["pick_order"] = 0
x_rec["role_code"] = 0
x_rec["side_code"] = 0

X_rec = pd.DataFrame([x_rec])
for f in pick_features:
    if f not in X_rec.columns:
        X_rec[f] = 0
X_rec = X_rec[pick_features].astype(np.int32)

# ---------- ğŸ¯ æ¨è–¦è‹±é›„ Top-5 ----------
blue_pick_ids = clean_ids(st.session_state.get("bp", []))
red_pick_ids = clean_ids(st.session_state.get("rp", []))
ban_ids = clean_ids(st.session_state.get("bb", []) +
                    st.session_state.get("rb", []))
pick_features = pick_model.feature_name()

if len(blue_pick_ids) >= 1:
    x_rec = {}
    for i in range(5):
        x_rec[f"pick_{i+1}"] = pad(blue_pick_ids)[i]
        x_rec[f"ban_{i+1}"] = pad(ban_ids)[i]
        x_rec[f"pick_wr{i+1}"] = 0
        x_rec[f"ban_wr{i+1}"] = 0
    x_rec["pick_order"] = 0
    x_rec["role_code"] = 0
    x_rec["side_code"] = 0

    X_rec = pd.DataFrame([x_rec])
    for f in pick_features:
        if f not in X_rec.columns:
            X_rec[f] = 0
    X_rec = X_rec[pick_features].astype(np.int32)

    try:
        probs = pick_model.predict(X_rec)[0]
        for i, cid in enumerate(encoder.classes_):
            cname = champ_name_map.get(cid, "")
            if cname in personal_boost:
                probs[i] += personal_boost[cname]


        topk = np.argsort(probs)[::-1][:5]

        # ğŸ›¡ï¸ é˜²æ­¢ topk è¶…å‡º encoder å¯ç”¨ç¯„åœ
        if np.max(topk) < len(encoder.classes_):
            top_champs = encoder.inverse_transform(topk)

            st.markdown("## ğŸ¯ æ¨è–¦è‹±é›„ Top-5")
            results = []
            for cid, prob in zip(top_champs, probs[topk]):
                name = champ_name_map.get(cid, f"ID {cid}")
                results.append(
                    {"ID": cid, "è‹±é›„": name, "é æ¸¬æ©Ÿç‡ (%)": f"{prob * 100:.2f}%"})
            st.table(pd.DataFrame(results))
        else:
            st.warning("âš ï¸ æ¨¡å‹é æ¸¬çµæœè¶…å‡º encoder ç¯„åœï¼Œè«‹æª¢æŸ¥æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨æ˜¯å¦åŒ¹é…ã€‚")

    except Exception as e:
        st.warning(f"âš ï¸ è—æ–¹æ¨è–¦é æ¸¬éŒ¯èª¤ï¼š{e}")
else:
    st.info("è«‹è‡³å°‘é¸æ“‡ä¸€ä½è—æ–¹è‹±é›„ä»¥å•Ÿç”¨æ¨è–¦åŠŸèƒ½ã€‚")


# å…ˆè¨­å®šé è¨­ï¼šè‹¥å°šæœªæ»¿è¶³ã€Œé›™æ–¹è‡³å°‘å„æœ‰ä¸€å€‹ Pickã€ï¼Œå°±å…ˆé¡¯ç¤º 50% : 50%
blue_strength = 0.5
red_strength = 0.5
show_wr = False  # æ˜¯å¦è¦é¡¯ç¤ºçœŸæ­£å¾æ¨¡å‹è¨ˆç®—çš„å‹ç‡

if len(blue_pick_ids) >= 1 and len(red_pick_ids) >= 1:
    # æ»¿è¶³æ¢ä»¶ï¼Œæ‰çœŸæ­£ build ç‰¹å¾µä¸¦å‘¼å«æ¨¡å‹
    show_wr = True

        # ---------- æ§‹é€  wr ç‰¹å¾µ ----------
    x_wr = {feat: 0 for feat in wr_features}

    for i in range(5):
        cid_b = pad(blue_pick_ids)[i]
        cid_r = pad(red_pick_ids)[i]

        x_wr[f"bp{i}"] = cid_b
        x_wr[f"rp{i}"] = cid_r

        # å¾ merged_output.csv å– win-rateï¼›è‹¥æŸ¥ä¸åˆ° â†’ 0.5
        x_wr[f"bp_wr{i}"] = WINRATE_LOOKUP.get(cid_b, 0.5)
        x_wr[f"rp_wr{i}"] = WINRATE_LOOKUP.get(cid_r, 0.5)

    # å…¶é¤˜æ•¸å€¼ç‰¹å¾µ (patch, duration, objectives, synergy) ä»ä¿æŒ 0
    X_wr = pd.DataFrame([x_wr])[wr_features].astype(np.float32)

    st.write("ğŸ“¤ è¼¸å…¥ç‰¹å¾µï¼š", X_wr)

    try:
        # model.predict å›å‚³è—éšŠå‹ç‡ï¼ˆå–®ä¸€ floatï¼‰
        blue_strength = wr_model.predict(X_wr)[0]
        red_strength = 1.0 - blue_strength
    except Exception as e:
        st.warning(f"âš ï¸ å‹ç‡é æ¸¬éŒ¯èª¤ï¼š{e}")
        # è‹¥å¤±æ•—ï¼Œå°±ä¿ç•™é è¨­ 50%ï¼š50%

# é¡¯ç¤ºèƒœç‡å€å¡Š
st.markdown("## âš”ï¸ é›™æ–¹éšŠä¼é ä¼°å‹ç‡ï¼ˆå‹•æ…‹ï¼‰")
if show_wr:
    st.markdown(f"ğŸ”µ è—éšŠé ä¼°å‹ç‡ï¼š**{blue_strength * 100:.2f}%**")
    st.markdown(f"ğŸ”´ ç´…éšŠé ä¼°å‹ç‡ï¼š**{red_strength * 100:.2f}%**")
else:
    st.markdown("ğŸ”µ è—éšŠé ä¼°å‹ç‡ï¼š**50.00%**")
    st.markdown("ğŸ”´ ç´…éšŠé ä¼°å‹ç‡ï¼š**50.00%**")
    st.info("è«‹å…ˆè®“é›™æ–¹å„è‡ªé¸è‡³å°‘ä¸€åè‹±é›„ (Pick) å¾Œï¼Œæ‰æœƒé¡¯ç¤ºå‹•æ…‹å‹ç‡ã€‚")

# ç”¨è¡¨æ ¼é¡¯ç¤ºåŸå§‹æ•¸å€¼ï¼ˆå¦‚æœæœ‰çœŸå¯¦è¨ˆç®—å‡ºçš„å‹ç‡ï¼Œå°±é¡¯ç¤ºè©²æ•¸å€¼ï¼›å¦å‰‡ä¿æŒ 50%ï¼‰
winrate_data = pd.DataFrame({
    "éšŠä¼": ["è—éšŠ", "ç´…éšŠ"],
    "é ä¼°å‹ç‡ (%)": [
        f"{(blue_strength * 100):.2f}%" if show_wr else "50.00%",
        f"{(red_strength * 100):.2f}%" if show_wr else "50.00%"
    ]
})
st.table(winrate_data)